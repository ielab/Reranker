#!/bin/bash

# set a job name
#SBATCH --job-name=reranker
#################

# a file for job output, you can check job progress
#SBATCH --output=reranker_slurm_output_%j.out
#################

# a file for errors
#SBATCH --error=reranker_slurm_output_%j.err
#################

# time needed for job
#SBATCH --time=00:15:00
#################

# gpus per node
#SBATCH --gres=gpu:3
#################

# cpus per job
#SBATCH --cpus-per-task=1
#################

# number of requested nodes
#SBATCH --nodes=1
#################

# memory per node
#SBATCH --mem=8GB
#################

# slurm will send a signal this far out before it kills the job
#SBATCH --signal=USR1@300
#################


# tasks per node
#SBATCH --tasks-per-node=1
#################

module load python/3.7.11
module load cuda
module load tensorflow/2.5.0-py39-cuda112
source ../../venv/bin/activate

# ls python3 run_agask.py --output_dir agask_model2 --model_name_or_path /scratch1/koo01a/Reranker/pt-bert-large-msmarco --do_train --max_len 64 --train_group_size 8 --per_device_train_batch_size 8 --per_device_eval_batch_size 8 --train_dir feature_json --overwrite_output_dir

srun python3 run_agask.py \
  --save_steps 2000 \
  --max_len 512 \
  --cache_dir cache\
  --per_device_train_batch_size 2 \
  --train_group_size 6 \
  --gradient_accumulation_steps 2 \
  --weight_decay 0.01 \
  --learning_rate 1e-6 \
  --num_train_epochs 10 \
  --dataloader_num_workers 8 \
  --fp16 \
  --do_train \
  --output_dir agask_model_custom_params \
  --model_name_or_path /scratch1/koo01a/Reranker/pt-bert-large-msmarco \
  --train_dir feature_json \
  --overwrite_output_dir
